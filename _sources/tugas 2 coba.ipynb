{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNNL6hCVoandlCXcGLmUMcF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install sastrawi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"noIhE3TNn2ms","executionInfo":{"status":"ok","timestamp":1729137449831,"user_tz":-420,"elapsed":4634,"user":{"displayName":"22-052 Yudha nuur cahyo","userId":"02966233732175847645"}},"outputId":"a3e49bea-ac29-455c-f0b6-a49c881a73b7"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting sastrawi\n","  Downloading Sastrawi-1.0.1-py2.py3-none-any.whl.metadata (909 bytes)\n","Downloading Sastrawi-1.0.1-py2.py3-none-any.whl (209 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.7/209.7 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: sastrawi\n","Successfully installed sastrawi-1.0.1\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hbCICxFhnqNd","executionInfo":{"status":"ok","timestamp":1729137456339,"user_tz":-420,"elapsed":951,"user":{"displayName":"22-052 Yudha nuur cahyo","userId":"02966233732175847645"}},"outputId":"07e17f23-1811-4dd7-ff40-5d216e2efeb6"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"]}],"source":["# Library untuk data manipulation\n","import pandas as pd\n","from tqdm import tqdm\n","import re\n","import string\n","\n","# Library untuk text preprocessing\n","import nltk\n","from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n","from nltk.tokenize import word_tokenize\n","from nltk.corpus import stopwords\n","nltk.download('stopwords')\n","nltk.download('punkt_tab')\n","\n","# Library untuk text vectorization/TF-IDF\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","# Library untuk save model\n","import pickle"]},{"cell_type":"code","source":[],"metadata":{"id":"WGUgdv_XnuhS"},"execution_count":null,"outputs":[]}]}